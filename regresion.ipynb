{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alexd\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexd\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, el método elegido es el de ``SVM`` y la técnica de escalado es ``StandardScaler``. Estos serán por lo tanto los métodos que utilicemos para realizar la evalución del rendimiento futuro, como se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en el conjunto de validación: 113942.31314937165\n",
      "RMSE en el conjunto de validación: 337.5534226598386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Carga los datos de entrenamiento en un DataFrame\n",
    "wind_ava = pd.read_csv('wind_ava.csv.gz', compression=\"gzip\")\n",
    "\n",
    "# Selecciona solo las columnas numéricas\n",
    "numerical_vars = wind_ava.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Asegúrate de que 'energy' no esté en las variables numéricas, ya que será tu variable objetivo\n",
    "numerical_vars = numerical_vars.drop('energy')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(wind_ava[numerical_vars], wind_ava['energy'], test_size=1/3, random_state=100472166, shuffle=False)\n",
    "\n",
    "# Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar el escalador a las características del conjunto de entrenamiento y transformarlas\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformar las características del conjunto de prueba usando el mismo escalador\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Dividir los datos de entrenamiento en un conjunto de entrenamiento más pequeño y un conjunto de validación\n",
    "X_train_inner, X_val, y_train_inner, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=100472166)\n",
    "\n",
    "# Definir el modelo SVM con los hiperparámetros seleccionados\n",
    "best_model = SVR(C=1000.0, shrinking=True, degree=2, gamma='auto')\n",
    "\n",
    "# Ajustar el modelo SVM en el conjunto de entrenamiento más pequeño\n",
    "best_model.fit(X_train_inner, y_train_inner)\n",
    "\n",
    "# Hacer predicciones en el conjunto de validación\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Calcular el error cuadrático medio (RMSE) en el conjunto de validación\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"MSE en el conjunto de validación: {mse}\")\n",
    "print(f\"RMSE en el conjunto de validación: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ``MSE`` obtenido es de 113940. Como era de esperar, al entrenarlo con todos los datos disponibles el error es significativamente menor que el resultado del ajuste de hiperparámetros (126242). El `` RMSE `` en cambio es de 337. Todos estos valores son por lo tanto los más bajos que hemos obtenido hasta ahora, pero únicamente con estas cifras no podemos determinar si nuestro modelo es bueno o no. Para ello nos guardamos el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Guardar el modelo en un archivo\n",
    "with open('modelo_final.pkl', 'wb') as file:\n",
    "    dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora utilizaremos este modelo para realizar predicciones con los datos de la competición y las guardaremos en el fichero `` predicciones.csv ``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Carga los datos de competición en un DataFrame\n",
    "competition_data = pd.read_csv('wind_comp.csv.gz', compression=\"gzip\")\n",
    "\n",
    "# Preprocesamiento: seleccionar variables numéricas\n",
    "numerical_vars_competition = competition_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Escalado de los datos de la competición\n",
    "X_competition_scaled = scaler.transform(competition_data[numerical_vars_competition])\n",
    "\n",
    "# Cargar el modelo final\n",
    "with open('modelo_final.pkl', 'rb') as file:\n",
    "    loaded_model = load(file)\n",
    "\n",
    "# Hacer predicciones en el conjunto de datos de la competición\n",
    "competition_predictions = loaded_model.predict(X_competition_scaled)\n",
    "\n",
    "# Guardar las predicciones en un archivo CSV\n",
    "pd.DataFrame(competition_predictions).to_csv('predicciones.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
