{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alexd\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexd\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\alexd\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(C=1000.0, degree=2, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=1000.0, degree=2, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(C=1000.0, degree=2, gamma='auto')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "wind_ava = pd.read_csv('wind_ava.csv.gz', compression=\"gzip\")\n",
    "\n",
    "# Elimina todas las variables meteorológicas que no correspondan a la localización de Sotavento (la localización 13)\n",
    "wind_ava = wind_ava.filter(regex='^(datetime|energy|.*\\.13)$')\n",
    "\n",
    "# Elimina las variables 'lai_hv.13' y 'v10n.13'\n",
    "if 'lai_hv.13' in wind_ava.columns and 'v10n.13' in wind_ava.columns:\n",
    "    wind_ava = wind_ava.drop(['lai_hv.13', 'v10n.13'], axis=1)\n",
    "\n",
    "# Vuelve a definir las variables numéricas\n",
    "numerical_vars = wind_ava.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Quitamos \"energy\" de las variables numéricas, ya que querremos usarla como variable objetivo\n",
    "numerical_vars = numerical_vars.drop('energy')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(wind_ava[numerical_vars], wind_ava['energy'], test_size=1/3, random_state=100472166, shuffle=False)\n",
    "\n",
    "# Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar el escalador a las características del conjunto de entrenamiento y transformarlas\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformar las características del conjunto de prueba usando el mismo escalador\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Dividir los datos de entrenamiento en un conjunto de entrenamiento más pequeño y un conjunto de validación\n",
    "X_train_inner, X_val, y_train_inner, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=100472166)\n",
    "\n",
    "# Definir el modelo SVM con los hiperparámetros seleccionados\n",
    "best_model = SVR(C=1000.0, shrinking=True, degree=2, gamma='auto')\n",
    "\n",
    "# Ajustar el modelo SVM en el conjunto de entrenamiento más pequeño\n",
    "best_model.fit(X_train_inner, y_train_inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar utilizaremos nuestro mejor modelo hasta el momento para comprobar si las predicciones para valores altos son peores que para valores bajos (o viceversa). Esto lo haremos comparando su RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 339.35857392117254\n",
      "RMSE para valores altos: 427.1333077701292\n",
      "RMSE para valores bajos: 219.31223444708536\n",
      "Las predicciones para valores altos son peores que para valores bajos.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predecir los valores de la variable objetivo para el conjunto de validación\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "# Calcular el error cuadrático medio (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Dividir las predicciones y los valores reales en grupos de altos y bajos\n",
    "# Aquí, asumimos que \"altos\" son aquellos valores mayores a la mediana y \"bajos\" son los menores\n",
    "median_energy = np.median(y_val)\n",
    "y_val_high = y_val[y_val > median_energy]\n",
    "y_val_low = y_val[y_val <= median_energy]\n",
    "y_pred_high = y_pred[y_val > median_energy]\n",
    "y_pred_low = y_pred[y_val <= median_energy]\n",
    "\n",
    "# Calcular el RMSE para los valores altos y bajos\n",
    "rmse_high = np.sqrt(mean_squared_error(y_val_high, y_pred_high))\n",
    "rmse_low = np.sqrt(mean_squared_error(y_val_low, y_pred_low))\n",
    "\n",
    "print(f\"RMSE para valores altos: {rmse_high}\")\n",
    "print(f\"RMSE para valores bajos: {rmse_low}\")\n",
    "\n",
    "# Comprobar si las predicciones para valores altos son peores que para valores bajos\n",
    "if rmse_high > rmse_low:\n",
    "    print(\"Las predicciones para valores altos son peores que para valores bajos.\")\n",
    "else:\n",
    "    print(\"Las predicciones para valores altos no son necesariamente peores que para valores bajos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión a clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo de clasificación: 0.8281743524952622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Eliminar la columna \"datetime\" del conjunto de datos\n",
    "wind_ava.drop([\"datetime\"], axis=1, inplace=True)\n",
    "\n",
    "# Determinar el tercer cuantil de la variable objetivo\n",
    "energy_quantile = wind_ava['energy'].quantile(0.25)\n",
    "\n",
    "# Clasificar los valores de energía como \"baja\" o \"alta\"\n",
    "wind_ava['energy_class'] = ['baja' if e < energy_quantile else 'alta' for e in wind_ava['energy']]\n",
    "\n",
    "# Convertir las etiquetas de clase a números\n",
    "label_encoder = LabelEncoder()\n",
    "wind_ava['energy_class_encoded'] = label_encoder.fit_transform(wind_ava['energy_class'])\n",
    "\n",
    "# Almacenamos en una variable todas las columnas no relacionadas con la variable objetivo\n",
    "excluir_columnas = ['energy', 'energy_class', 'energy_class_encoded']\n",
    "numerical_vars = [col for col in wind_ava.columns if col not in excluir_columnas]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "    wind_ava[numerical_vars], \n",
    "    wind_ava['energy_class_encoded'], \n",
    "    test_size=1/3, \n",
    "    random_state=100472166\n",
    ")\n",
    "\n",
    "# Ajustar el escalador a las características del conjunto de entrenamiento y transformarlas\n",
    "scaler = StandardScaler()\n",
    "X_train_class_scaled = scaler.fit_transform(X_train_class)\n",
    "X_test_class_scaled = scaler.transform(X_test_class)\n",
    "\n",
    "# Definir y entrenar un modelo de clasificación\n",
    "classifier = RandomForestClassifier(random_state=100472166)\n",
    "classifier.fit(X_train_class_scaled, y_train_class)\n",
    "\n",
    "# Predecir las clases para el conjunto de prueba\n",
    "y_pred_class = classifier.predict(X_test_class_scaled)\n",
    "\n",
    "# Calcular la precisión del modelo de clasificación\n",
    "accuracy = classifier.score(X_test_class_scaled, y_test_class)\n",
    "print(f\"Precisión del modelo de clasificación: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros:  {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      1189\n",
      "           1       0.71      0.54      0.61       394\n",
      "\n",
      "    accuracy                           0.83      1583\n",
      "   macro avg       0.78      0.73      0.75      1583\n",
      "weighted avg       0.82      0.83      0.82      1583\n",
      "\n",
      "[[1103   86]\n",
      " [ 182  212]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    wind_ava[numerical_vars], \n",
    "    wind_ava['energy_class_encoded'], \n",
    "    test_size=1/3, \n",
    "    random_state=100472166\n",
    ")\n",
    "\n",
    "# Definir el modelo\n",
    "model = RandomForestClassifier(random_state=100472166)\n",
    "\n",
    "# Definir los hiperparámetros a ajustar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda en cuadrícula para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros: \", grid_search.best_params_)\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir las clases para el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar las métricas\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para SVC: {'C': 10.0, 'gamma': 0.01}\n",
      "Mejores hiperparámetros para DecisionTreeClassifier: {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
      "Mejores hiperparámetros para KNeighborsClassifier: {'n_neighbors': 9, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Hiperparámetros para SVC\n",
    "svc_params = {\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'gamma': np.logspace(-3, 3, 7)\n",
    "    # 'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Hiperparámetros para DecisionTreeClassifier\n",
    "dt_params = {\n",
    "    'max_depth': np.arange(1, 10),\n",
    "    'min_samples_split': np.arange(2, 10),\n",
    "    'min_samples_leaf': np.arange(1, 10)\n",
    "}\n",
    "\n",
    "# Hiperparámetros para KNeighborsClassifier\n",
    "knn_params = {\n",
    "    'n_neighbors': np.arange(1, 10),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Ajustar el escalador a las características del conjunto de entrenamiento y transformarlas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SVC\n",
    "svc = SVC(random_state=42)\n",
    "svc_search = GridSearchCV(svc, svc_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "svc_search.fit(X_train_scaled, y_train)\n",
    "print(\"Mejores hiperparámetros para SVC:\", svc_search.best_params_)\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_search = GridSearchCV(dt, dt_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "dt_search.fit(X_train_scaled, y_train)\n",
    "print(\"Mejores hiperparámetros para DecisionTreeClassifier:\", dt_search.best_params_)\n",
    "\n",
    "# KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn_search = GridSearchCV(knn, knn_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "knn_search.fit(X_train_scaled, y_train)\n",
    "print(\"Mejores hiperparámetros para KNeighborsClassifier:\", knn_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
