{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de los datos y filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_ava = pd.read_csv('wind_ava.csv.gz', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 1\n",
    "En el primer apartado, comenzamos con un EDA o Análisis Exploratorio de los Datos que nos servirá para comprender mejor el problema al que nos enfrentamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina todas las variables meteorológicas que no correspondan a la localización de Sotavento (la localización 13)\n",
    "wind_ava = wind_ava.filter(regex='^(datetime|energy|.*\\.13)$')\n",
    "\n",
    "# Número de instancias y características\n",
    "print(f'Número de instancias: {wind_ava.shape[0]}')\n",
    "print(f'Número de características: {wind_ava.shape[1]}')\n",
    "\n",
    "# Variables categóricas y numéricas\n",
    "categorical_vars = wind_ava.select_dtypes(include=['object']).columns\n",
    "numerical_vars = wind_ava.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(f'Variables categóricas: {categorical_vars}')\n",
    "print(f'Variables numéricas: {numerical_vars}')\n",
    "\n",
    "# Comprueba si hay valores faltantes y qué variables los tienen\n",
    "missing_values = wind_ava.isnull().sum()\n",
    "print(f'Valores faltantes por variable:\\n{missing_values[missing_values > 0]}')\n",
    "\n",
    "# Columnas constantes\n",
    "constant_columns = [col for col in wind_ava.columns if wind_ava[col].nunique() <= 1]\n",
    "print(f'Columnas constantes: {constant_columns}')\n",
    "\n",
    "# Elimina las columnas constantes\n",
    "wind_ava = wind_ava.loc[:, wind_ava.apply(pd.Series.nunique) != 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, estamos ante un problema de ``regresión`` (al ser valores continuos) y en el cual tenemos ``4748 instancias``. Cada instancia a su vez presenta 22 variables númericas, 1 variable 'datetime' y una variable objetivo 'energy'. Cabe destacar además que el conjunto de datos no presenta valores faltantes ni columnas que sean constantes, por lo que no hay que hacer ningún tipo de preproceso relativo a esos problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de correlación\n",
    "Podemos realizar una matriz de correlación para comprobar qué variables están fuertemente relacionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos un analisis de la correlación de las variables númericas\n",
    "correlation = wind_ava[numerical_vars].corr()\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(correlation, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos resultados podemos ver que tanto las variables `` lai_lv.13`` y `` lai_hv.13 ``, como las variables `` v10.13 `` y `` v10n.13``, tienen una correlacion de aproximadamente 1. Por lo tanto, podemos quitar una de cada pareja, ya que dan información redundante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina las variables 'lai_hv.13' y 'v10n.13'\n",
    "if 'lai_hv.13' in wind_ava.columns and 'v10n.13' in wind_ava.columns:\n",
    "    wind_ava = wind_ava.drop(['lai_hv.13', 'v10n.13'], axis=1)\n",
    "\n",
    "# Vuelve a definir las variables numéricas\n",
    "numerical_vars = wind_ava.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Realizamos un analisis de la correlación de las variables númericas\n",
    "correlation = wind_ava[numerical_vars].corr()\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(correlation, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que sigue habiendo variables muy correlacionadas entre ellas, llegando a haber resultados de 0.99, pero en ningún caso aparece un 1 fuera de la diagonal. Además, con esta matriz podemos ver que la variable que más correlación tiene con la energía producida es `` p59.162 `` (Vertical integral of divergence of kinetic energy) con un grado casi del 50%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución valores variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el próposito de ver como se distribuyen los datos en nuestras variables hemos creado los siguientes histogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Número de variables numéricas\n",
    "num_vars = len(numerical_vars)\n",
    "\n",
    "# Calcula el número de filas y columnas para los subplots\n",
    "num_cols = 4  # número máximo de columnas\n",
    "num_rows = np.ceil(num_vars / num_cols).astype(int)\n",
    "\n",
    "# Crea una figura y un conjunto de subtramas\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(6*num_cols, 4*num_rows))\n",
    "\n",
    "# Aplana el array de subplots para facilitar su recorrido\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Para cada variable numérica, crea un histograma en su respectivo subplot\n",
    "for i, col in enumerate(numerical_vars):\n",
    "    axs[i].hist(wind_ava[col], bins=30, alpha=0.5, label=col)\n",
    "    axs[i].set_title(f'Distribución de {col}')\n",
    "    axs[i].set_xlabel(col)\n",
    "    axs[i].set_ylabel('Frecuencia')\n",
    "    axs[i].legend(loc='upper right')\n",
    "\n",
    "# Elimina los subplots vacíos si el número de variables no es múltiplo de 4\n",
    "if num_vars % num_cols != 0:\n",
    "    for j in range(i+1, num_rows*num_cols):\n",
    "        fig.delaxes(axs[j])\n",
    "\n",
    "# Ajusta el espacio entre los subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la figura con todos los histogramas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos histogramas nos ayudan a conocer mejor como se distribuyen los datos  y qué valores mínimos y máximos toman nuestras variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energía producida por meses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si realizamos la media por meses de la energía producida y mostramos un gráfico de diferentes años podemos hacernos una idea de en qué meses se produce más energía:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se asegura de que 'datetime' es de tipo datetime\n",
    "wind_ava['datetime'] = pd.to_datetime(wind_ava['datetime'])\n",
    "\n",
    "# Lista de colores para cada año\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "# Iterar sobre cada año único en los datos\n",
    "for year, color in zip(wind_ava['datetime'].dt.year.unique(), colors):\n",
    "    # Filtra los datos para el año actual\n",
    "    filtered_data = wind_ava[wind_ava['datetime'].dt.year == year]\n",
    "    \n",
    "    # Agrupa por mes y calcula la media de 'energy' para el año actual\n",
    "    monthly_energy = filtered_data.groupby(filtered_data['datetime'].dt.to_period('M')).mean()\n",
    "    \n",
    "    # Crea un gráfico para el año actual\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Traza la media mensual de 'energy' para el año actual con el color correspondiente\n",
    "    plt.plot(monthly_energy.index.to_timestamp(), monthly_energy['energy'], color=color)\n",
    "    \n",
    "    # Configura etiquetas y título\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Energía Media')\n",
    "    plt.title(f'Media Mensual de Energía para el Año {year}')\n",
    "    \n",
    "    # Muestra el gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, los meses del año en los que menos energía se suele producir son julio y agosto, mientras que generalmente se produce más energía en noviembre o marzo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los outliers identifican el número de datos que están fuera de la distribución. Nos ayudan a identificar si se han producido errores de medición, anomalías o cambios en la distribución de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada variable numérica, visualizar los outliers\n",
    "for col in numerical_vars:\n",
    "    Q1 = wind_ava[col].quantile(0.25)\n",
    "    Q3 = wind_ava[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = wind_ava[(wind_ava[col] < (Q1 - 1.5 * IQR)) | (wind_ava[col] > (Q3 + 1.5 * IQR))]\n",
    "    print(f\"Outliers en {col}: {outliers[col].count()}\")\n",
    "\n",
    "# Lista de variables para las que visualizar outliers\n",
    "variables = ['energy', 'p55.162.13', 'cape.13', 'p59.162.13', 'sp.13', 'iews.13', 'inss.13', 'fsr.13']\n",
    "\n",
    "# Para cada variable, creamos un gráfico de caja\n",
    "for var in variables:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    boxplot = plt.boxplot(wind_ava[var], vert=False)\n",
    "    plt.setp(boxplot['boxes'], color='blue')\n",
    "    plt.title(f'Boxplot de {var}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos resultados podemos ver que las variables con el mayor número de outliers son ``cape.13`` e ``inss.13``, con 697 y 431 outliers respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2\n",
    "La evaluación ``outer`` del modelo se llevará a cabo por medio de la evualuación train/test, ya que disponemos de un gran número de datos. Por otro lado, en la evaluavión ``inner`` se utilizará más de un método de evaluación con el fin de probarlos y comparar sus resultados. Esto incluye evaluación cruzada y el uso de Grid-search (para ajustar múltiples hiperparámetros).\n",
    "\n",
    "En cuanto a la métrica, en general hemos utilizado ``MSE`` y ``RSME``. Hemos decidido hacerlo con estas medidas ya que están en las mismas unidades que la variable objetivo, lo que facilita su interpretación. Además, tanto el MSE como el RMSE penalizan más los errores grandes que los pequeños, debido a que cada error se eleva al cuadrado antes de hacer la media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 3\n",
    "En primer lugar, y usando el método KNN, vamos a comprobar cuál es el mejor método de escalado para nuestros datos. Para ello utilizaremos validación cruzada y nos basaremos en el error cuadrático medio negativo (o RMSE), por lo que el modelo con el resultado más pequeño será el modelo más preciso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Quitamos \"energy\" de las variables numéricas, ya que querremos usarla como variable objetivo\n",
    "numerical_vars = numerical_vars.drop('energy')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (evaluación externa)\n",
    "X_train, X_test, y_train, y_test = train_test_split(wind_ava[numerical_vars], wind_ava['energy'], test_size=1/3, random_state=100472166, shuffle=False)\n",
    "\n",
    "# Definir los métodos de escalado para evaluar\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "# Evauluación interna con 3-fold time series cross-validation\n",
    "inner = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Diccionario para almacenar los resultados de la evaluación interna\n",
    "inner_scores = {}\n",
    "\n",
    "# Pipeline para StandardScaler\n",
    "knn_standard = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "scores_std = cross_val_score(knn_standard, X_train, y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['StandardScaler'] = -scores_std.mean()\n",
    "\n",
    "# Pipeline para MinMaxScaler\n",
    "knn_minmax = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "scores_minmax = cross_val_score(knn_minmax, X_train, y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['MinMaxScaler'] = -scores_minmax.mean()\n",
    "\n",
    "# Pipeline para RobustScaler\n",
    "knn_robust = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "scores_robust = cross_val_score(knn_robust, X_train, y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['RobustScaker'] = -scores_robust.mean()\n",
    "\n",
    "# Imprimimos los resultados\n",
    "for scaler_name, score in inner_scores.items():\n",
    "    print(f\"Variable Name: {scaler_name}\")\n",
    "    print(f\"Variable Score: {score}\")\n",
    "    print()\n",
    "\n",
    "# Elegimos el mejor método de escalado según el RMSE\n",
    "mejor_scaler = min(inner_scores, key=inner_scores.get)\n",
    "print(f\"El mejor método de escalado es {mejor_scaler} con un RMSE de {inner_scores[min(inner_scores, key=inner_scores.get)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 4\n",
    "De manera similar, ahora evaluaremos y mediremos los tiempos de distintos métodos. Primero lo haremos con sus hiperparámetros por defecto, como se muestra a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Crear instancias de los modelos\n",
    "knn = KNeighborsRegressor()\n",
    "tree = DecisionTreeRegressor()\n",
    "linear = LinearRegression()\n",
    "lasso = Lasso()\n",
    "svm = SVR()\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Crear listas para almacenar los tiempos de entrenamiento y los errores\n",
    "times = {name: [] for name in scalers}\n",
    "errors = {name: [] for name in scalers}\n",
    "\n",
    "models = [knn, tree, linear, lasso, svm, dummy]\n",
    "model_names = ['KNN', 'Árboles de Regresión', 'Regresión Lineal', 'Regresión Lasso', 'SVM', 'Dummy']\n",
    "\n",
    "# Entrenar y evaluar los modelos con diferentes métodos de escalado\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    if scaler is not None:\n",
    "        # Escala los datos de entrenamiento\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        # Escala los datos de prueba\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        # Si no se utiliza escalado, usa los datos originales\n",
    "        X_train_scaled = X_train\n",
    "        X_test_scaled = X_test\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "        times[scaler_name].append(train_time)\n",
    "\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        error = mean_squared_error(y_test, y_pred)\n",
    "        errors[scaler_name].append(error)\n",
    "\n",
    "        print(f\"Modelo: {name}, Escalado: {scaler_name}\")\n",
    "        print(f\"Tiempo de entrenamiento: {train_time} segundos\")\n",
    "        print(f\"Error cuadrático medio: {error}\")\n",
    "        print(\"------------------------\")\n",
    "\n",
    "\n",
    "# Crea una figura y un conjunto de subtramas\n",
    "fig, axs = plt.subplots(2, figsize=(12, 6))\n",
    "\n",
    "# Crea una lista con los nombres de los escaladores\n",
    "scaler_names = list(scalers.keys())\n",
    "\n",
    "# Crea diagramas de barras para los tiempos de entrenamiento\n",
    "for i, scaler_name in enumerate(scaler_names):\n",
    "    axs[0].bar(np.arange(len(model_names)) + i*0.1, times[scaler_name], width=0.1, label=scaler_name)\n",
    "\n",
    "axs[0].set_xticks(np.arange(len(model_names)) + len(scalers)*0.1/2)\n",
    "axs[0].set_xticklabels(model_names)\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Tiempo de entrenamiento')\n",
    "axs[0].set_ylabel('Segundos')\n",
    "\n",
    "# Crea diagramas de barras para los errores\n",
    "for i, scaler_name in enumerate(scaler_names):\n",
    "    axs[1].bar(np.arange(len(model_names)) + i*0.1, errors[scaler_name], width=0.1, label=scaler_name)\n",
    "\n",
    "axs[1].set_xticks(np.arange(len(model_names)) + len(scalers)*0.1/2)\n",
    "axs[1].set_xticklabels(model_names)\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Error cuadrático medio')\n",
    "axs[1].set_ylabel('Error')\n",
    "\n",
    "# Muestra la figura\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos gráficos nos ayudan a ver que, con los hiperparámetros por defecto, el modelo con el menor error es ``KNN``. Este modelo es también el más beneficioso en cuanto al tiempo, llegando a ser casi tan instantáneo como el \"Dummy\". El resto de errores, como cabe esperar, son prácticamente todos menores que el conseguido simplemente haciendo la media (en el \"Dummy\"). Todos excepto los obtenidos con SVM y los escaladores MinMax y Robust. Esto significa que sería preferible devolver la media antes que usar los valores devueltos por el modelo SVM con sus parámetros por omisión, sobre todo teniendo en cuenta que también es el modelo que más tarda en ejecutar.\n",
    "\n",
    "En cuanto a los escaladores, las diferencias entre ellos son bastante pequeñas, por lo que a partir de ahora utilizaremos el ``StandardScaler``. Consideramos que es lo mejor, ya que el enunciado nos sugería que utilizaramos el mejor escalador para KNN y porque nos será beneficioso más adelante, al ser también el escalador que mejor funciona en SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch\n",
    "Ahora volveremos a evaluar los modelos, pero esta vez probando distintos valores para los hiperparámetros y mediante el uso de un procedimiento sistemático como ``GridSearchCV``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mejor_scaler = StandardScaler()\n",
    "X_train_scaled = mejor_scaler.fit_transform(X_train)\n",
    "X_test_scaled = mejor_scaler.transform(X_test)\n",
    "\n",
    "# Hiperparámetros\n",
    "knn_params = {\n",
    "    'n_neighbors': list(range(1, 31)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "tree_params = {\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_leaf_nodes': [10, 20, 30],\n",
    "    'min_impurity_decrease': [0.0, 0.1],\n",
    "    'criterion': ['squared_error'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.5]\n",
    "}\n",
    "linear_params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "lasso_params = {\n",
    "    'alpha': [0.1, 0.5, 1, 5, 10],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': [5000, 10000],\n",
    "    'tol': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'positive': [True, False],\n",
    "    'selection': ['cyclic', 'random'],\n",
    "    'random_state': [None, 100472166]\n",
    "}\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100, 1000, 2500],\n",
    "    'shrinking': [True, False],\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'coef0': [0, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Realizamos GridSearchCV para cada modelo\n",
    "knn_grid = GridSearchCV(KNeighborsRegressor(), knn_params, cv=inner)\n",
    "tree_grid = GridSearchCV(DecisionTreeRegressor(), tree_params, cv=inner)\n",
    "linear_grid = GridSearchCV(LinearRegression(), linear_params, cv=inner)\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=inner)\n",
    "svm_grid = GridSearchCV(SVR(), svm_params, cv=inner)\n",
    "\n",
    "# Ajusta KNN con los mejores hiperparámetros\n",
    "start_time = time.time()\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para KNN\n",
    "best_knn_params = knn_grid.best_params_\n",
    "best_knn_score = knn_grid.best_score_\n",
    "y_pred = knn_grid.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"KNN:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_knn_params)\n",
    "print(\"Mejor Puntuación:\", best_knn_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"Tiempo de entrenamiento:\", train_time)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Ajusta árboles de decisión con los mejores hiperparámetros\n",
    "start_time = time.time()\n",
    "tree_grid.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para árboles de decisión\n",
    "best_tree_params = tree_grid.best_params_\n",
    "best_tree_score = tree_grid.best_score_\n",
    "y_pred = tree_grid.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Árbol de Decisión:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_tree_params)\n",
    "print(\"Mejor Puntuación:\", best_tree_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"Tiempo de entrenamiento:\", train_time)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Ajusta regresión lineal con los mejores hiperparámetros\n",
    "start_time = time.time()\n",
    "linear_grid.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para regresión lineal\n",
    "best_linear_params = linear_grid.best_params_\n",
    "best_linear_score = linear_grid.best_score_\n",
    "y_pred = linear_grid.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Regresión Lineal:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_linear_params)\n",
    "print(\"Mejor Puntuación:\", best_linear_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"Tiempo de entrenamiento:\", train_time)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Ajusta regresuón Lasso con los mejores hiperparámetros\n",
    "start_time = time.time()\n",
    "lasso_grid.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para regresión Lasso\n",
    "best_lasso_params = lasso_grid.best_params_\n",
    "best_lasso_score = lasso_grid.best_score_\n",
    "y_pred = lasso_grid.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Lasso:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_lasso_params)\n",
    "print(\"Mejor Puntuación:\", best_lasso_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"Tiempo de entrenamiento:\", train_time)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Ajusta SVM con los mejores hiperparámetros\n",
    "start_time = time.time()\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para SVM\n",
    "best_svm_params = svm_grid.best_params_\n",
    "best_svm_score = svm_grid.best_score_\n",
    "y_pred = svm_grid.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"SVM:\") \n",
    "print(\"Mejores Hiperparámetros:\", best_svm_params)\n",
    "print(\"Mejor Puntuación:\", best_svm_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"Tiempo de entrenamiento:\", train_time)\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comparar los valores que acabamos de obtener y los valores de los modelos por omisión mediante el siguiente gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una figura con un tamaño específico (ancho, alto)\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "# Crea una lista con los nombres de los modelos\n",
    "model_names = ['KNN', 'Árbol de Decisión', 'Regresión Lineal', 'Lasso', 'SVM', 'Dummy']\n",
    "\n",
    "# Cre listas para almacenar las puntuaciones y los errores\n",
    "scores = [best_knn_score, best_tree_score, best_linear_score, best_lasso_score, best_svm_score]\n",
    "errors_now = [mean_squared_error(y_test, knn_grid.predict(X_test_scaled)),\n",
    "          mean_squared_error(y_test, tree_grid.predict(X_test_scaled)),\n",
    "          mean_squared_error(y_test, linear_grid.predict(X_test_scaled)),\n",
    "          mean_squared_error(y_test, lasso_grid.predict(X_test_scaled)),\n",
    "          mean_squared_error(y_test, svm_grid.predict(X_test_scaled)),\n",
    "          errors['StandardScaler'][5]]\n",
    "\n",
    "# Crea diagramas de barras para los errores\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(model_names))\n",
    "\n",
    "bar1 = ax.bar(index, errors_now, bar_width, color='blue', label='MSE con ajuste')\n",
    "bar2 = ax.bar(index + bar_width, errors['StandardScaler'], bar_width, color='orange', label='MSE por defecto')\n",
    "\n",
    "ax.set_xlabel('Modelos')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Comparación de errores')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(model_names)\n",
    "ax.legend()\n",
    "\n",
    "# Ajusta el diseño y muestra la figura\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, y basándonos en los resultados obtenidos hasta el momento, llegamos a las siguientes conclusiones:\n",
    "\n",
    "Una vez hecho el ajuste de hiperparámetros ``SVM`` obtuvo la puntuación más alta, con un 0.65, lo que indica que ahora es el modelo que mejor se ajusta a nuestros datos. Y es que el error cuadrático medio es mucho menor que cuando se usaban los parámetros por defecto, llegando a bajar de 427590 a 159220. Por todas estas razones consideramos que SVM es el mejor modelo para usar con los datos proporcionados, incluso habiendo sido el peor en las evaluaciones anteriores.\n",
    "\n",
    "El ajuste de hiperparámetros ha sido por lo tanto una gran ayuda a la hora de obtener valores más precisos, no sólo para SVM, sino también para el resto de modelos. Y es que hay modelos que han reducido poco su error (como KNN), otros que lo han reducido significativamente (como árboles de decisión y SVM) y el resto se han mantenido igual (regresión lineal y regresión Lasso).\n",
    "\n",
    "En cuanto a velocidad, el método más rápido obviamente es el \"Dummy\" con 0.0 segundos (es decir, es un método prácticamente instantáneo para este conjunto de datos). Sin embargo, los resultados del resto de métodos son obviamente mejores que los obtenidos con un \"DummyRegressor\", lo que indica que cualquier modelo de los propuestos es más útil que simplemente asumir el valor medio.\n",
    "\n",
    "En general, existe un equilibrio entre el tiempo de ejecución y la mejora de resultados. Por ejemplo, el modelo SVM es el que más tarda en entrenar, pero al mismo tiempo es el que mejor resultado presenta. En cambio, la regresión lineal tarda menos de 1 segundo en ajustarse pero eso provoca que tenga un MSE bastante elevado, además de ser idéntico al que obtuvo con sus valores por omisión.\n",
    "\n",
    "Por último, nos parece importante destacar que hemos llegado a este resultado en parte gracias al preproceso y al análisis de las variables que realizamos. Gracias a él por ejemplo pudimos eliminar dos variables con una alta correlacción, y si hubiera habido valores nulos o columnas de muy baja correlacción con la variable objetivo también nos habría ayudado. Algunos modelos (como los árboles de decisión) también proporcionan información sobre la importancia de los atributos. Por ejemplo, se puede obtener la importancia de los atributos en uno de estos árboles mediante el atributo feature_importances_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
