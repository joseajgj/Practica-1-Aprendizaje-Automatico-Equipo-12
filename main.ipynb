{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de los datos y filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_ava = pd.read_csv('wind_ava.csv.gz', compression=\"gzip\")\n",
    "wind_ava = wind_ava.filter(regex='^(datetime|energy|.*\\.13)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 1\n",
    "EDA o Análisis Exploratorio de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de instancias y características\n",
    "print(f'Número de instancias: {wind_ava.shape[0]}')\n",
    "print(f'Número de características: {wind_ava.shape[1]}')\n",
    "\n",
    "# Variables categóricas y numéricas\n",
    "categorical_vars = wind_ava.select_dtypes(include=['object']).columns\n",
    "numerical_vars = wind_ava.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(f'Variables categóricas: {categorical_vars}')\n",
    "print(f'Variables numéricas: {numerical_vars}')\n",
    "\n",
    "# Valores faltantes\n",
    "zero_count = (wind_ava == 0).sum().sum()\n",
    "print(f\"Número de valores que son 0: {zero_count}\")\n",
    "\n",
    "# Columnas constantes\n",
    "constant_columns = [col for col in wind_ava.columns if wind_ava[col].nunique() <= 1]\n",
    "print(f'Columnas constantes: {constant_columns}')\n",
    "\n",
    "# Determinar si es un problema de regresión o clasificación\n",
    "if wind_ava['energy'].nunique() > 2:\n",
    "    print('Es un problema de regresión')\n",
    "else:\n",
    "    print('Es un problema de clasificación')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(wind_ava[numerical_vars], wind_ava['energy'], test_size=0.3, random_state=100472166)\n",
    "\n",
    "# Definir los métodos de escalado para evaluar\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "# Crear un imputador para reemplazar los valores 0 con la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "# Evaluar KNN con diferentes métodos de escalado\n",
    "results = {}\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Imputar los valores 0 en los datos de entrenamiento\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    \n",
    "    # Escalar los datos de entrenamiento\n",
    "    X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "    \n",
    "    # Entrenar el modelo KNN\n",
    "    knn = KNeighborsRegressor()\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Imputar los valores 0 en los datos de prueba\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos de prueba\n",
    "    X_test_scaled = scaler.transform(X_test_imputed)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    score = knn.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Almacenar los resultados\n",
    "    results[scaler_name] = score\n",
    "\n",
    "for scaler_name, score in results.items():\n",
    "    print(f\"Variable Name: {scaler_name}\")\n",
    "    print(f\"Variable Score: {score}\")\n",
    "    print()\n",
    "\n",
    "# Elegir el método de escalado con el mejor rendimiento\n",
    "mejor_scaler = max(results, key=results.get)\n",
    "print(f\"El mejor método de escalado es {mejor_scaler} con un puntaje de {results[mejor_scaler]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Crear instancias de los modelos\n",
    "knn = KNeighborsRegressor()\n",
    "tree = DecisionTreeRegressor()\n",
    "linear = LinearRegression()\n",
    "lasso = Lasso()\n",
    "svm = SVR()\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Crear listas para almacenar los tiempos de entrenamiento y los errores\n",
    "times = []\n",
    "errors = []\n",
    "\n",
    "# Entrenar y evaluar los modelos\n",
    "models = [knn, tree, linear, lasso, svm, dummy]\n",
    "model_names = ['KNN', 'Árboles de Regresión', 'Regresión Lineal', 'Regresión Lasso', 'SVM', 'Dummy']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    times.append(train_time)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "    errors.append(error)\n",
    "    \n",
    "    print(f\"Modelo: {name}\")\n",
    "    print(f\"Tiempo de entrenamiento: {train_time} segundos\")\n",
    "    print(f\"Error cuadrático medio: {error}\")\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hiperparámetros\n",
    "knn_params = {'n_neighbors': [3, 5, 7]}\n",
    "tree_params = {'max_depth': [None, 5, 10]}\n",
    "linear_params = {'fit_intercept': [True, False]}\n",
    "lasso_params = {'alpha': [0.1, 0.5, 1.0]}\n",
    "svm_params = {'C': [1.0, 10.0, 100.0]}\n",
    "\n",
    "# Realizamos GridSearchCV para cada modelo\n",
    "knn_grid = GridSearchCV(KNeighborsRegressor(), knn_params)\n",
    "tree_grid = GridSearchCV(DecisionTreeRegressor(), tree_params)\n",
    "linear_grid = GridSearchCV(LinearRegression(), linear_params)\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params)\n",
    "svm_grid = GridSearchCV(SVR(), svm_params)\n",
    "\n",
    "# Ajusta los modelos con los mejores hiperparámetros\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "tree_grid.fit(X_train_scaled, y_train)\n",
    "linear_grid.fit(X_train_scaled, y_train)\n",
    "lasso_grid.fit(X_train_scaled, y_train)\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para cada modelo\n",
    "best_knn_params = knn_grid.best_params_\n",
    "best_knn_score = knn_grid.best_score_\n",
    "\n",
    "best_tree_params = tree_grid.best_params_\n",
    "best_tree_score = tree_grid.best_score_\n",
    "\n",
    "best_linear_params = linear_grid.best_params_\n",
    "best_linear_score = linear_grid.best_score_\n",
    "\n",
    "best_lasso_params = lasso_grid.best_params_\n",
    "best_lasso_score = lasso_grid.best_score_\n",
    "\n",
    "best_svm_params = svm_grid.best_params_\n",
    "best_svm_score = svm_grid.best_score_\n",
    "\n",
    "# Imprime los resultados\n",
    "print(\"KNN:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_knn_params)\n",
    "print(\"Mejor Puntuación:\", best_knn_score)\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"Árbol de Decisión:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_tree_params)\n",
    "print(\"Mejor Puntuación:\", best_tree_score)\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"Regresión Lineal:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_linear_params)\n",
    "print(\"Mejor Puntuación:\", best_linear_score)\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"Lasso:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_lasso_params)\n",
    "print(\"Mejor Puntuación:\", best_lasso_score)\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"SVM:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_svm_params)\n",
    "print(\"Mejor Puntuación:\", best_svm_score)\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en los resultados obtenidos, llegamos a las siguientes conclusiones:\n",
    "\n",
    "En términos de puntuación, la Regresión Lineal obtuvo un 1.0, lo que indica un muy buen ajuste a los datos. En cuanto a factores como la interpretación de los resultados y el rendimiento computacional la Regresión Lineal también mostraba muy buenos resultados, por lo que consideramos que es el mejor método.\n",
    "\n",
    "En cuanto a velocidad, el método más rápido es el \"Dummy\" con 0.0 segundos (es decir, es un método prácticamente instantáneo para este conjunto de datos). Sin embargo, los resultados del resto de métodos son obviamente mejores que los obtenidos con un \"DummyRegressor\". Si bien es cierto que este tipo de regresor nos permite ahorrar tiempo, el error cuadrático medio es mucho más alto que el de los demás.\n",
    "\n",
    "En general, existe un equilibrio entre el tiempo de ejecución y la mejora de resultados. Por ejemplo, los árboles de regresión tardan más que el método KNN, pero al mismo tiempo KNN muestra peores resultados que los árboles de regresióm. Esto en nuestro análisis de los datos no se cumple siempre de todos modos, ya que el método de regresión lineal es más rápido que varios de los demás y aun así presenta el mejor resultado.\n",
    "\n",
    "El ajuste de hiperparámetros también ayuda a mejorar el rendimiento de los modelos en comparación con los valores por defecto. En este caso, hemos utilizado GridSearchCV para buscar los mejores hiperparámetros para cada modelo. Por ejemplo, para el método SMV y para la regresión Lasso se consideran como los mejores hiperparámetros el 100.0 y el 0.1, respectivamente. En cambio, el resto de métodos (regresión lineal, KNN y árboles de regresión).\n",
    "\n",
    "Por último, podríamos extraer atributos relevantes dependiendo del modelo utilizado, ya que algunos (como los árboles de decisión) proporcionan información sobre la importancia de los atributos. Por ejemplo, se puede obtener la importancia de los atributos en uno de estos árboles mediante el atributo feature_importances_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
