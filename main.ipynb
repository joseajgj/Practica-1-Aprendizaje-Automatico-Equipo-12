{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de los datos y filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_ava = pd.read_csv('wind_ava.csv.gz', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 1\n",
    "EDA o Análisis Exploratorio de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina todas las variables meteorológicas que no correspondan a la localización de Sotavento (la localización 13)\n",
    "wind_ava = wind_ava.filter(regex='^(datetime|energy|.*\\.13)$')\n",
    "\n",
    "# Número de instancias y características\n",
    "print(f'Número de instancias: {wind_ava.shape[0]}')\n",
    "print(f'Número de características: {wind_ava.shape[1]}')\n",
    "\n",
    "# Variables categóricas y numéricas\n",
    "categorical_vars = wind_ava.select_dtypes(include=['object']).columns\n",
    "numerical_vars = wind_ava.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(f'Variables categóricas: {categorical_vars}')\n",
    "print(f'Variables numéricas: {numerical_vars}')\n",
    "\n",
    "# Comprueba si hay valores faltantes y qué variables los tienen\n",
    "missing_values = wind_ava.isnull().sum()\n",
    "print(f'Valores faltantes por variable:\\n{missing_values[missing_values > 0]}')\n",
    "\n",
    "# Columnas constantes\n",
    "constant_columns = [col for col in wind_ava.columns if wind_ava[col].nunique() <= 1]\n",
    "print(f'Columnas constantes: {constant_columns}')\n",
    "\n",
    "# Elimina las columnas constantes\n",
    "wind_ava = wind_ava.loc[:, wind_ava.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Determinar si es un problema de regresión o clasificación\n",
    "if wind_ava['energy'].nunique() > 2:\n",
    "    print('Es un problema de regresión')\n",
    "else:\n",
    "    print('Es un problema de clasificación')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de correlación\n",
    "Podemos realizar una matriz de correlación para ver que variables están fuertemente relacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos un analisis de la correlación de las variables númericas\n",
    "correlation = wind_ava[numerical_vars].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos resultados podemos ver que tanto las variables `` lai_lv.13`` y `` lai_hv.13 ``, como las variables `` v10.13 `` y `` v10n.13``, tienen una correlacion de 1. Por lo tanto, podemos quitar una de cada pareja, ya que dan información redundante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina las variables 'lai_hv.13' y 'v10n.13'\n",
    "if 'lai_hv.13' in wind_ava.columns and 'v10n.13' in wind_ava.columns:\n",
    "    wind_ava = wind_ava.drop(['lai_hv.13', 'v10n.13'], axis=1)\n",
    "\n",
    "# Vuelve a definir las variables numéricas\n",
    "numerical_vars = wind_ava.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Realizamos un analisis de la correlación de las variables númericas\n",
    "correlation = wind_ava[numerical_vars].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que sigue habiendo variables muy correlacionadas entre ellas, llegando a haber resultados de 0.99, pero en ningún caso aparece un 1 fuera de la diagonal. Además, con esta matriz podemos ver que la variable que más correlación tiene con la energía producida es `` p59.162 `` (Vertical integral of divergence of kinetic energy) con un grado casi del 50%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Para cada variable numérica, crear un histograma\n",
    "for col in numerical_vars:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    wind_ava[col].hist(bins=30, alpha=0.5, label=col)\n",
    "    plt.title(f'Distribución de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos histogramas nos ayudan a conocer mejor como se distribuyen los datos  y qué valores mínimos y máximos toman nuestras variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que 'datetime' es de tipo datetime\n",
    "wind_ava['datetime'] = pd.to_datetime(wind_ava['datetime'])\n",
    "\n",
    "# Lista de colores para cada año\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "# Iterar sobre cada año único en los datos\n",
    "for year, color in zip(wind_ava['datetime'].dt.year.unique(), colors):\n",
    "    # Filtrar los datos para el año actual\n",
    "    filtered_data = wind_ava[wind_ava['datetime'].dt.year == year]\n",
    "    \n",
    "    # Agrupar por mes y calcular la media de 'energy' para el año actual\n",
    "    monthly_energy = filtered_data.groupby(filtered_data['datetime'].dt.to_period('M')).mean()\n",
    "    \n",
    "    # Crear un gráfico para el año actual\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Trazar la media mensual de 'energy' para el año actual con el color correspondiente\n",
    "    plt.plot(monthly_energy.index.to_timestamp(), monthly_energy['energy'], color=color)\n",
    "    \n",
    "    # Configurar etiquetas y título\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Energía Media')\n",
    "    plt.title(f'Media Mensual de Energía para el Año {year}')\n",
    "    \n",
    "    # Mostrar el gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos la mayoría de los meses en el año que menos energía se producce son en julio y agosto, mientras que cuando más energía se produce suele ser noviembre o marzo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada variable numérica, visualizar los outliers\n",
    "for col in numerical_vars:\n",
    "    Q1 = wind_ava[col].quantile(0.25)\n",
    "    Q3 = wind_ava[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = wind_ava[(wind_ava[col] < (Q1 - 1.5 * IQR)) | (wind_ava[col] > (Q3 + 1.5 * IQR))]\n",
    "    print(f\"Outliers en {col}: {outliers[col].count()}\")\n",
    "\n",
    "# Lista de variables para las que visualizar outliers\n",
    "variables = ['energy', 'p55.162.13', 'cape.13', 'p59.162.13', 'sp.13', 'iews.13', 'inss.13', 'fsr.13']\n",
    "\n",
    "# Para cada variable, creamos un gráfico de caja\n",
    "for var in variables:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    boxplot = plt.boxplot(wind_ava[var], vert=False)\n",
    "    plt.setp(boxplot['boxes'], color='blue')\n",
    "    plt.title(f'Boxplot de {var}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los outliers identifican el número de datos que están fuera de la distribución. Nos ayudan a identificar si se han producido errores de medición, anomalías o cambios en la distribución de los datos. Con estos resultados podemos ver que las variables con el mayor número de outliers son cape.13 y inss.13, con 697 y 431 outliers respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2\n",
    "La evaluación ``outer`` del modelo se llevará a cabo por medio de la evualuación train/test, ya que disponemos de un gran número de datos. Por otro lado, en la evaluavión ``inner`` se utilizará más de un método de evaluación con el fin de probarlos y comparar sus resultados. Esto incluye train/test, evaluación cruzada, y el uso de Grid-search (para ajustar múltiples hiperparámetros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 3\n",
    "En primer lugar, y usando el método KNN, vamos a comprobar cuál es el mejor método de escalado para nuestros datos. Para ello nos vamos a basar en el error cuadrático medio negativo (o RMSE), por lo que el modelo con el resultado más pequeño será el modelo más preciso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Quitamos \"energy\" de las variables numéricas, ya que querremos usarla como variable objetivo\n",
    "numerical_vars = numerical_vars.drop('energy')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (evaluación externa)\n",
    "X_train, X_test, y_train, y_test = train_test_split(wind_ava[numerical_vars], wind_ava['energy'], test_size=1/3, random_state=100472166, shuffle=False)\n",
    "\n",
    "# Definir los métodos de escalado para evaluar\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "# Evauluación interna con 3-fold time series cross-validation\n",
    "inner = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Diccionario para almacenar los resultados de la evaluación interna\n",
    "inner_scores = {}\n",
    "\n",
    "# Pipeline para StandardScaler\n",
    "knn_standard = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "scores_std = cross_val_score(knn_standard, X_train, y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['StandardScaler'] = -scores_std.mean()\n",
    "\n",
    "# Pipeline para MinMaxScaler\n",
    "knn_minmax = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "scores_minmax = cross_val_score(knn_minmax, X_train, y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['MinMaxScaler'] = -scores_minmax.mean()\n",
    "\n",
    "# Pipeline para RobustScaler\n",
    "knn_robust = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "scores_robust = cross_val_score(knn_robust, X_train, y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['RobustScaker'] = -scores_robust.mean()\n",
    "\n",
    "# Imprimimos los resultados\n",
    "for scaler_name, score in inner_scores.items():\n",
    "    print(f\"Variable Name: {scaler_name}\")\n",
    "    print(f\"Variable Score: {score}\")\n",
    "    print()\n",
    "\n",
    "# Elegimos el mejor método de escalado según el RMSE\n",
    "mejor_scaler = min(inner_scores, key=inner_scores.get)\n",
    "print(f\"El mejor método de escalado es {mejor_scaler} con un RMSE de {inner_scores[min(inner_scores, key=inner_scores.get)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 4\n",
    "De manera similar, ahora evaluaremos y mediremos los tiempos de distintos métodos. Primero lo haremos con sus hiperparámetros por defecto, como se muestra a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Crear instancias de los modelos\n",
    "knn = KNeighborsRegressor()\n",
    "tree = DecisionTreeRegressor()\n",
    "linear = LinearRegression()\n",
    "lasso = Lasso()\n",
    "svm = SVR()\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Crear listas para almacenar los tiempos de entrenamiento y los errores\n",
    "times = {name: [] for name in scalers}\n",
    "errors = {name: [] for name in scalers}\n",
    "\n",
    "models = [knn, tree, linear, lasso, svm, dummy]\n",
    "model_names = ['KNN', 'Árboles de Regresión', 'Regresión Lineal', 'Regresión Lasso', 'SVM', 'Dummy']\n",
    "\n",
    "# Entrenar y evaluar los modelos con diferentes métodos de escalado\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    if scaler is not None:\n",
    "        # Escalar los datos de entrenamiento\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        # Escalar los datos de prueba\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        # Si no se utiliza escalado, usar los datos originales\n",
    "        X_train_scaled = X_train\n",
    "        X_test_scaled = X_test\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "        times[scaler_name].append(train_time)\n",
    "\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        error = mean_squared_error(y_test, y_pred)\n",
    "        errors[scaler_name].append(error)\n",
    "\n",
    "        print(f\"Modelo: {name}, Escalado: {scaler_name}\")\n",
    "        print(f\"Tiempo de entrenamiento: {train_time} segundos\")\n",
    "        print(f\"Error cuadrático medio: {error}\")\n",
    "        print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch\n",
    "Ahora volveremos a evaluar los modelos, pero esta vez probando distintos valores para los hiperparámetros y mediante el uso de un procedimiento sistemático como ``GridSearchCV``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hiperparámetros\n",
    "knn_params = {\n",
    "    'n_neighbors': list(range(1, 31)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "}\n",
    "tree_params = {\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_leaf_nodes': [10, 20, 30],\n",
    "    'min_impurity_decrease': [0.0, 0.1],\n",
    "    'criterion': ['squared_error'],\n",
    "    'splitter': ['best'],\n",
    "    'min_weight_fraction_leaf': [0.0],\n",
    "}\n",
    "\n",
    "linear_params = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "}\n",
    "lasso_params = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': [10000],\n",
    "    'precompute': [True, False],\n",
    "    'tol': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'warm_start': [True, False],\n",
    "    'positive': [True, False],\n",
    "    'selection': ['cyclic', 'random'],\n",
    "    'random_state': [100472166]\n",
    "}\n",
    "svm_params = {\n",
    "    'C': [0.001, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "    'shrinking': [True, False],\n",
    "    'gamma':['scale', 'auto'],\n",
    "    'degree': [2,3,4,5]\n",
    "}\n",
    "\n",
    "# Realizamos GridSearchCV para cada modelo\n",
    "knn_grid = GridSearchCV(KNeighborsRegressor(), knn_params)\n",
    "tree_grid = GridSearchCV(DecisionTreeRegressor(), tree_params)\n",
    "linear_grid = GridSearchCV(LinearRegression(), linear_params)\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params)\n",
    "svm_grid = GridSearchCV(SVR(), svm_params)\n",
    "\n",
    "# Ajusta los modelos con los mejores hiperparámetros\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para KNN\n",
    "best_knn_params = knn_grid.best_params_\n",
    "best_knn_score = knn_grid.best_score_\n",
    "y_pred = knn_grid.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"KNN:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_knn_params)\n",
    "print(\"Mejor Puntuación:\", best_knn_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para árboles de decisión\n",
    "tree_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_tree_params = tree_grid.best_params_\n",
    "best_tree_score = tree_grid.best_score_\n",
    "y_pred = tree_grid.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"Árbol de Decisión:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_tree_params)\n",
    "print(\"Mejor Puntuación:\", best_tree_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para regresión lineal\n",
    "linear_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_linear_params = linear_grid.best_params_\n",
    "best_linear_score = linear_grid.best_score_\n",
    "y_pred = linear_grid.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"Regresión Lineal:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_linear_params)\n",
    "print(\"Mejor Puntuación:\", best_linear_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para Lasso\n",
    "lasso_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_lasso_params = lasso_grid.best_params_\n",
    "best_lasso_score = lasso_grid.best_score_\n",
    "y_pred = lasso_grid.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"Lasso:\")\n",
    "print(\"Mejores Hiperparámetros:\", best_lasso_params)\n",
    "print(\"Mejor Puntuación:\", best_lasso_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Obtenemos los mejores hiperparámetros y puntuaciones para SVM\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_svm_params = svm_grid.best_params_\n",
    "best_svm_score = svm_grid.best_score_\n",
    "y_pred = svm_grid.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"SVM:\") \n",
    "print(\"Mejores Hiperparámetros:\", best_svm_params)\n",
    "print(\"Mejor Puntuación:\", best_svm_score)\n",
    "print(\"Error cuadrático medio:\", mse)\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en los resultados obtenidos, llegamos a las siguientes conclusiones:\n",
    "\n",
    "En términos de puntuación, SVM obtuvo la más alta con un 0.65, lo que indica que es el modelo que mejor se ajusta a los datos. Observamos además que el error cuadrático medio es mucho menor ahora que cuando se usaban los parámetros por defecto, llegando a bajar de 427590 a 126242. No sólo eso, si no que ahora el error cuadrático medio de SVM también es el menor de todo el ajuste de hiperarámetros. Por todas estas razones consideramos que es el mejor modelo para usar con nuestros datos.\n",
    "\n",
    "En cuanto a velocidad, el método más rápido obviamente es el \"Dummy\" con 0.0 segundos (es decir, es un método prácticamente instantáneo para este conjunto de datos). Sin embargo, los resultados del resto de métodos son obviamente mejores que los obtenidos con un \"DummyRegressor\". Si bien es cierto que este tipo de regresor nos permite ahorrar tiempo, el error cuadrático medio es mucho más alto que el de los demás.\n",
    "\n",
    "En general, existe un equilibrio entre el tiempo de ejecución y la mejora de resultados. Por ejemplo, los árboles de regresión tardan más que el método KNN, pero al mismo tiempo KNN muestra peores resultados que los árboles de regresióm. Esto en nuestro análisis de los datos no se cumple siempre de todos modos, ya que el método de regresión lineal es más rápido que varios de los demás y aun así presenta el mejor resultado.\n",
    "\n",
    "El ajuste de hiperparámetros nos ha ayudado por lo tanto a mejorar el rendimiento y la precisión de los modelos en comparación con los valores por defecto. Hay modelos que han reducido poco su error (por ejemplo en regresión lineal y regresión Lasso) y otros que lo han reducido significativamente (como KNN, árboles de decisión y SVM), pero ninguno ha empeorado.\n",
    "\n",
    "Por último, podríamos extraer atributos relevantes dependiendo del modelo utilizado, ya que algunos (como los árboles de decisión) proporcionan información sobre la importancia de los atributos. Por ejemplo, se puede obtener la importancia de los atributos en uno de estos árboles mediante el atributo feature_importances_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definición de modelos\n",
    "models = {\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'Árboles de regresión': DecisionTreeRegressor(),\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'SVM': SVR()\n",
    "}\n",
    "\n",
    "# Realiza la validación cruzada para cada modelo\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    print(f'Modelo: {model_name}')\n",
    "    print(f'Puntuaciones de validación cruzada: {scores}')\n",
    "    print(f'Puntuación media de validación cruzada: {scores.mean()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto a los resultados obtenidos en la validación cruzada podemos ver que KNN tiene una media de 0.823 lo que indica un buen rendimiento. Modelos como árboles de regresión, lasso o regresión lineal nos dan una media de 1 lo que nos puede estar indicando que el modelo esta sobreajustado o está realizandolo muy bien. Mientras que SVM obtiene una puntuación negativa indicando un mal rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
